{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89218551",
   "metadata": {},
   "source": [
    "### IMDB Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ee7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d280dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = requests.get(\"https://www.imdb.com/list/ls055592025/\").text\n",
    "soup = BeautifulSoup(movies, \"lxml\") #soup is our html file\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e749bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = soup.find(\"div\", class_=\"lister-item-content\")\n",
    "#print(movie_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8569b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather\n"
     ]
    }
   ],
   "source": [
    "title = movie_info.h3.a.text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc86985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972\n"
     ]
    }
   ],
   "source": [
    "year = movie_info.find(\"span\", class_=\"lister-item-year text-muted unbold\").text.strip(\"()\")\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fdf906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crime, Drama            \n"
     ]
    }
   ],
   "source": [
    "genre = movie_info.find(\"span\", class_=\"genre\").text\n",
    "print(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd34c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_file = open(\"movies_scrape.csv\", \"w\", newline=\"\", encoding=\"utf-8\") #create and write to a csv file \n",
    "csv_writer = csv.writer(new_csv_file)\n",
    "csv_writer.writerow([\"Title\", \"Year\", \"Genre\"])\n",
    "\n",
    "page = 1\n",
    "\n",
    "while page != 2:\n",
    "    movies = requests.get(\"https://www.imdb.com/list/ls055592025/\").text\n",
    "    soup = BeautifulSoup(movies, \"lxml\") \n",
    "    \n",
    "    for movie in soup.find_all(\"div\", class_=\"lister-item-content\"):\n",
    "        title = movie.h3.a.text\n",
    "        year = movie.find(\"span\", class_=\"lister-item-year text-muted unbold\").text.strip(\"()\")\n",
    "        genre = movie.find(\"span\", class_=\"genre\").text\n",
    "        \n",
    "        csv_writer.writerow([title, year, genre])\n",
    "        \n",
    "    \n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a748024",
   "metadata": {},
   "source": [
    "### Congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c190c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "congress = requests.get(\"https://www.loc.gov/search/?q=cats&sp=1\").text\n",
    "soup = BeautifulSoup(congress, \"lxml\") #soup is our html file\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37965727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "congress_info = soup.find(\"div\", class_=\"description\")\n",
    "#print(congress_info.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1585aa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "            \n",
      "                \n",
      "                    Cats\n",
      "                \n",
      "            \n",
      "        \n",
      "\n",
      "        \n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "title = congress_info.div.a.text \n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed639fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \n",
      "            \n",
      "\n",
      "                \n",
      "                    \n",
      "                        \n",
      "                          1 print : tinted lithograph ; sheet 48.5 x 57.3 cm. | Print shows the faces and front paws of two sleeping cats.\n",
      "                        \n",
      "                    \n",
      "                \n",
      "\n",
      "            \n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "item_description = congress_info.find(\"span\", class_=\"item-description-abstract\").text\n",
    "print(item_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baaf2182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_file = open(\"cat_congress.csv\", \"w\", newline=\"\", encoding=\"utf-8\") #create and write to a csv file \n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Title\", \"url\", \"Item Description\"])\n",
    "\n",
    "page = 1\n",
    "\n",
    "while page != 6:\n",
    "    congress = requests.get(f\"https://www.loc.gov/search/?q=cats&sp={page}\").text\n",
    "    soup = BeautifulSoup(congress, \"lxml\") \n",
    "    \n",
    "    for cat in soup.find_all(\"div\", class_=\"description\"):\n",
    "        title = cat.find(\"span\", class_=\"item-description-title\").text.strip() #title\n",
    "        #print(title)\n",
    "        \n",
    "        url = cat.a.get(\"href\") \n",
    "        #print(url)        \n",
    "        \n",
    "        try:\n",
    "            item_description = cat.find(\"span\", class_=\"item-description-abstract\").text.strip()\n",
    "        except AttributeError:\n",
    "            item_description = \"No data listed\"\n",
    "        #print(item_description)\n",
    "        \n",
    "        csv_writer.writerow([title, url, item_description])\n",
    "\n",
    "    page += 1\n",
    "    \n",
    "csv_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81727b21",
   "metadata": {},
   "source": [
    "#### Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92688057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bonus preparation\n",
    "congress_bonus = soup.find(\"div\", class_=\"description\")\n",
    "#print(congress_info.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1205a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                        Childs & Inman - Fenderich, Charles\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "#bonus, isolating the conitrbutor names\n",
    "contributor = congress_bonus.li.span.text\n",
    "print(contributor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "322cb61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li class=\"date\">\n",
      "<strong class=\"search-results-label\">Date:</strong>\n",
      "<span>: 1832</span>\n",
      "</li>\n"
     ]
    }
   ],
   "source": [
    "congress_date = soup.find(\"li\", class_=\"date\")\n",
    "print(congress_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b41457ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1832\n"
     ]
    }
   ],
   "source": [
    "#bonus, isolating the date\n",
    "item_date = congress_date.span.text.strip(\": \")\n",
    "print(item_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d8d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why isnt this working\n",
    "\n",
    "new_csv_file = open(\"congress_bonus.csv\", \"w\", newline=\"\", encoding=\"utf-8\") #create and write to a csv file \n",
    "csv_writer = csv.writer(new_csv_file)\n",
    "csv_writer.writerow([\"Contributor\", \"year\"])\n",
    "\n",
    "page = 1\n",
    "\n",
    "while page != 6:\n",
    "    congress = requests.get(f\"https://www.loc.gov/search/?q=cats&sp={page}\").text    \n",
    "    soup = BeautifulSoup(congress, \"lxml\") \n",
    "    \n",
    "    for cat in soup.find_all(\"div\", class_=\"description\"):\n",
    "        try:\n",
    "            contributor = cat.li.span.text\n",
    "        except AttributeError:\n",
    "            contributor = \"No data listed\"\n",
    "        #print(contributor)\n",
    "        \n",
    "        item_date = cat.span.text.strip(\": \")\n",
    "        #print(item_date)\n",
    "        \n",
    "        csv_writer.writerow([contributor, year])\n",
    "        \n",
    "    page += 1\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126afd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
